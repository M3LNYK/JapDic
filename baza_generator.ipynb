{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JapDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for testownik generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.0, made by Vik\n",
    "\n",
    "In this code I want to create simple quizes to learn words for japanese A1 course. I have an app, which reades `.txt` files and creates questions from them. `001.txt` structure is following:\n",
    "```\n",
    "X0100                           <- Shows the correct answer 1,2,3,4. In this case it's answer 2\n",
    "1. What colour is sun?          <- Question line\n",
    "Blue                            <- Answers below\n",
    "Yellow\n",
    "Green\n",
    "Red\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial plan:\n",
    "- [X] Read notion table \n",
    "- [X] Convert to pd\n",
    "- [X] Create question for each word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from notion_client import Client\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read last data added\n",
    "def get_latest_data_file():\n",
    "    \"\"\"\n",
    "    Gets the most recently added file in the data directory\n",
    "\n",
    "    Returns:\n",
    "        str: Name of the most recently added file\n",
    "    \"\"\"\n",
    "    data_dir = \"data\"\n",
    "    files = []\n",
    "\n",
    "    # Get all files in data directory with creation times\n",
    "    for filename in os.listdir(data_dir):\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            creation_time = os.path.getctime(filepath)\n",
    "            files.append((filename, creation_time))\n",
    "\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    # Sort by creation time and get most recent\n",
    "    latest_file = sorted(files, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    print(f\"Latest file found: {latest_file}\")\n",
    "    return latest_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_notion():\n",
    "    \"\"\"\n",
    "    Gets all words from the Notion table using existing retriever.ipynb methods\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with english and japanese columns\n",
    "    \"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv(\"locals.env\")\n",
    "    token = os.getenv(\"NOTION_TOKEN\")\n",
    "    table_id = os.getenv(\"NOTION_TABLE_ID\")\n",
    "\n",
    "    # Initialize Notion client\n",
    "    client = Client(auth=token)\n",
    "\n",
    "    words = []\n",
    "    start_cursor = None\n",
    "\n",
    "    while True:\n",
    "        # Get page of results\n",
    "        response = client.blocks.children.list(\n",
    "            block_id=table_id, start_cursor=start_cursor, page_size=100\n",
    "        )\n",
    "\n",
    "        # Skip header row and process data rows\n",
    "        for row in response[\"results\"][1:]:\n",
    "            if row[\"type\"] == \"table_row\":\n",
    "                cells = row[\"table_row\"][\"cells\"]\n",
    "                if len(cells) >= 4:  # Ensure we have enough cells\n",
    "                    english = cells[3][0][\"text\"][\"content\"] if cells[3] else \"\"\n",
    "                    japanese = cells[1][0][\"text\"][\"content\"] if cells[1] else \"\"\n",
    "                    words.append((english, japanese))\n",
    "\n",
    "        # Check if there are more pages\n",
    "        if not response.get(\"has_more\"):\n",
    "            break\n",
    "\n",
    "        start_cursor = response[\"next_cursor\"]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(words, columns=[\"english\", \"japanese\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  english japanese\n",
      "0     she   KANOJO\n",
      "1      he     KARE\n",
      "2    name    NAMAE\n",
      "3     bag    KABAN\n",
      "4   clock    TOKEI\n"
     ]
    }
   ],
   "source": [
    "# Replace the file reading code with Notion data retrieval\n",
    "data_pd = get_words_from_notion()\n",
    "\n",
    "# latest_file = get_latest_data_file()\n",
    "# data_pd = pd.read_csv(\n",
    "#     f\"data/{latest_file}\", sep=\"=\", header=None, names=[\"english\", \"japanese\"]\n",
    "# )\n",
    "\n",
    "print(data_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_file(index, japanese_word, english_word, all_english_words):\n",
    "    \"\"\"\n",
    "    Generates a single question file in the specified format\n",
    "\n",
    "    Args:\n",
    "        index (int): Question number (for filename)\n",
    "        japanese_word (str): The Japanese word to test\n",
    "        english_word (str): The correct English translation\n",
    "        all_english_words (list): List of all English words to choose wrong answers from\n",
    "    \"\"\"\n",
    "    # Create baza directory if it doesn't exist\n",
    "    if not os.path.exists(\"baza\"):\n",
    "        os.makedirs(\"baza\")\n",
    "\n",
    "    # Get 3 random wrong answers\n",
    "    wrong_answers = random.sample(\n",
    "        [w for w in all_english_words if w != english_word], 3\n",
    "    )\n",
    "\n",
    "    # Generate filename with leading zeros\n",
    "    filename = f\"baza/{index:04d}_JAPA1.txt\"\n",
    "\n",
    "    # Combine correct and wrong answers\n",
    "    answers = wrong_answers + [english_word]\n",
    "\n",
    "    # Randomly shuffle answers and keep track of correct position\n",
    "    correct_position = len(answers) - 1  # Initial position of correct answer\n",
    "    random.shuffle(answers)\n",
    "    correct_position = answers.index(\n",
    "        english_word\n",
    "    )  # New position after shuffle (0-based)\n",
    "\n",
    "    # Create the correct answer marker (e.g., X1000, X0100, X0010, X0001)\n",
    "    answer_marker = [\"0\"] * len(answers)\n",
    "    answer_marker[correct_position] = \"1\"\n",
    "    answer_marker = \"X\" + \"\".join(answer_marker)\n",
    "\n",
    "    # Write to file\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{answer_marker}\\n\")  # Mark correct answer\n",
    "        f.write(f\"{index}. {japanese_word}\\n\")  # Question\n",
    "        for answer in answers:\n",
    "            f.write(f\"{answer}\\n\")  # Write each answer option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 164 question files in the 'baza' folder\n"
     ]
    }
   ],
   "source": [
    "# Get all English words for wrong answers\n",
    "all_english = data_pd[\"english\"].tolist()\n",
    "\n",
    "# Generate a file for each Japanese word\n",
    "for index, row in data_pd.iterrows():\n",
    "    generate_question_file(\n",
    "        index + 1,  # Start from 1\n",
    "        row[\"japanese\"],\n",
    "        row[\"english\"],\n",
    "        all_english,\n",
    "    )\n",
    "\n",
    "print(f\"Generated {len(data_pd)} question files in the 'baza' folder\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
